{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "Trains a Fully Convolutional Network (FCN) with ResNet-50 as feature extractor.<br>\n",
    "The neural network is trained on a labeled binary dataset of agricultural irrigation ponds.<br>\n",
    "We used [Google Map Static API](https://developers.google.com/maps/documentation/maps-static/intro) \n",
    "as a source of high-resolution satellite imagery:<br>\n",
    "\n",
    "\n",
    "Required Third-party libraries:\n",
    "    \n",
    "    * keras\n",
    "    * numpy\n",
    "\n",
    "Required custum modules\n",
    "    \n",
    "    * ./functions/image\n",
    "    * ./functions/load_data\n",
    "    * ./functions/utils\n",
    "    * ./neural_network/resnet\n",
    "    * ./neural_network/metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Required libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Custom modules\n",
    "sys.path.append('../functions')\n",
    "from utils import need_time\n",
    "from utils import save_pickle\n",
    "from utils import files_paths\n",
    "from load_data import DataGenerator\n",
    "from image import display_image_and_labels\n",
    "from image import display_image_labels_and_prediction\n",
    "\n",
    "sys.path.append('../neural_network')\n",
    "import resnet\n",
    "from metrics import dice_coeff\n",
    "from metrics import dice_loss\n",
    "from metrics import crossentropy_dice_loss\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "seed = np.random.seed(1234)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files paths\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Input parameters\n",
    "\n",
    "# Train and validation paths\n",
    "train_images_path = '../Data/Images/Train_Images'\n",
    "validation_images_path = '../Data/Images/Validation_Images'\n",
    "\n",
    "data_suffix = '_data.png'\n",
    "labels_suffix = '_labels.png'\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Set the train paths\n",
    "train_ims_paths = files_paths(train_images_path, \n",
    "                              nested_carpets=True, exts=data_suffix)\n",
    "train_labels_paths = [i.replace(data_suffix, \n",
    "                                labels_suffix) for i in train_ims_paths]\n",
    "\n",
    "# Set the validation paths\n",
    "validation_ims_paths = files_paths(validation_images_path, \n",
    "                                   nested_carpets=True, exts=data_suffix)\n",
    "validation_labels_paths = [i.replace(data_suffix, \n",
    "                                     labels_suffix) for i in validation_ims_paths]\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Input parameters\n",
    "\n",
    "# Image pre-processing\n",
    "im_prep_funcs = ['crop', 'scaling']\n",
    "im_prep_params = {'crop_size': 20}\n",
    "\n",
    "labels_prep_funcs = ['crop', 'pick channels']\n",
    "labels_prep_params = {'crop_size': 20, 'idxs_channel': 0}\n",
    "\n",
    "aug_funcs = ['flip', 'rotate']\n",
    "aug_params = {'p' : 0.5}\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "n_classes = 2\n",
    "shuffle = True\n",
    "epochs = 1\n",
    "steps_per_epoch = 1\n",
    "train_batch_size = 1\n",
    "validation_batch_size = 1\n",
    "validation_steps = 1\n",
    "class_weights = {0: 0.5, 1: 1.5}\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "# `RMSprop`, `Adam` \n",
    "optimizer = 'RMSprop'\n",
    "\n",
    "# `crossentropy dice loss`, `dice loss`\n",
    "loss = 'crossentropy dice loss'\n",
    "\n",
    "# `dice_coeff`, `[]`\n",
    "accuracy = '[]'\n",
    "\n",
    "# Steps without any improve before stop\n",
    "early_stop_steps = 4\n",
    "\n",
    "# Load ResNet pretrained with ImageNet\n",
    "use_pretreining_imagent = True\n",
    "\n",
    "# Freeze pretrained layers\n",
    "freeze = False\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Outputs, create a carpet with the current time\n",
    "t = time.localtime()\n",
    "base_name = '{}-{}-{}_{}_{}_{}'.format(t.tm_year,\n",
    "                                       t.tm_mon,\n",
    "                                       t.tm_mday,\n",
    "                                       t.tm_hour,\n",
    "                                       t.tm_min,\n",
    "                                       t.tm_sec)\n",
    "\n",
    "base_name = '../neural_network/Model/{}'.format(base_name)\n",
    "if not os.path.exists(base_name):\n",
    "    os.mkdir(base_name)\n",
    "    os.mkdir(os.path.join(base_name, 'log'))\n",
    "\n",
    "path_save_input_params = os.path.join(base_name, 'input_params.pkl')\n",
    "path_save_weights = os.path.join(base_name, 'weights.h5')\n",
    "path_tensorboard_log = os.path.join(base_name, 'log', 'log_out')\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "input_train_parameters = {'ims_paths' : train_ims_paths,\n",
    "                          'labels_paths' : train_labels_paths,\n",
    "                          'class_weights' : class_weights,\n",
    "                          'batch_size' : train_batch_size,\n",
    "                          'steps_per_epoch' : steps_per_epoch,\n",
    "                          'shuffle' : shuffle,\n",
    "                          'n_classes' : n_classes,\n",
    "                          'im_prep_funcs' : im_prep_funcs,\n",
    "                          'im_prep_params': im_prep_params,\n",
    "                          'labels_prep_funcs' : labels_prep_funcs,\n",
    "                          'labels_prep_params' : labels_prep_params,\n",
    "                          'aug_funcs' : aug_funcs,\n",
    "                          'aug_params' : aug_params}\n",
    "\n",
    "input_validation_parameters = {'ims_paths' : validation_ims_paths,\n",
    "                               'labels_paths' : validation_labels_paths,\n",
    "                               'class_weights' : class_weights,\n",
    "                               'batch_size' : validation_batch_size,\n",
    "                               'steps_per_epoch' : validation_steps,\n",
    "                               'shuffle' : shuffle,\n",
    "                               'n_classes' : n_classes,\n",
    "                               'im_prep_funcs' : im_prep_funcs,\n",
    "                               'im_prep_params': im_prep_params,\n",
    "                               'labels_prep_funcs' : labels_prep_funcs,\n",
    "                               'labels_prep_params' : labels_prep_params}\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "# Fit the train and validation generators\n",
    "train_generator = DataGenerator(**input_train_parameters)\n",
    "validation_generator = DataGenerator(**input_validation_parameters)\n",
    "\n",
    "print('\\nTrain set information:')\n",
    "print(train_generator)\n",
    "print('\\nValidation set information:')\n",
    "print(validation_generator)\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display one batch of samples from the training set\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "if class_weights:\n",
    "    X, y, sample_weights = train_generator[0]\n",
    "else:\n",
    "    X, y = train_generator[0]\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    display_image_and_labels(X[i,...,:3], \n",
    "                             y.reshape(train_generator.batch_size,\n",
    "                                       train_generator.h,\n",
    "                                       train_generator.w,\n",
    "                                       train_generator.n_classes)[i,...,1], \n",
    "                             colormap='gray')\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FCN model\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "input_shape = [train_generator.h, \n",
    "               train_generator.w, \n",
    "               train_generator.channels]    \n",
    "    \n",
    "# Build the model\n",
    "model = resnet.ResNet50_FCN(input_shape, n_classes, \n",
    "                            use_pretreining_imagent, freeze)\n",
    "\n",
    "# Optimizer\n",
    "if optimizer == 'RMSprop':\n",
    "    optimizer_function = RMSprop(lr=learning_rate) \n",
    "elif optimizer == 'Adam':\n",
    "    optimizer_function = Adam(lr=learning_rate)\n",
    "\n",
    "# Loss function\n",
    "if loss == 'crossentropy dice loss':\n",
    "    loss_function = crossentropy_dice_loss \n",
    "elif loss == 'dice loss':\n",
    "    loss_function = dice_loss\n",
    "\n",
    "# Accuracy\n",
    "if accuracy == 'dice_coeff':\n",
    "    accuracy_function = [dice_coeff]\n",
    "\n",
    "else:\n",
    "    accuracy_function = []\n",
    "\n",
    "# Compile the model\n",
    "if class_weights is not None:    \n",
    "    model.compile(optimizer=optimizer_function, \n",
    "                  loss=loss_function, \n",
    "                  metrics=accuracy_function,\n",
    "                  sample_weight_mode='temporal')\n",
    "else:\n",
    "    model.compile(optimizer=optimizer_function, \n",
    "                  loss=loss_function, \n",
    "                  metrics=accuracy_function)\n",
    "\n",
    "# Training callbacks\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=early_stop_steps,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4),\n",
    "             \n",
    "             LearningRateScheduler(resnet.lr_scheduler_function),\n",
    "             \n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath=path_save_weights,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True),\n",
    "             \n",
    "             TensorBoard(log_dir=path_tensorboard_log)]\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training parameters\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "params = {'seed' : seed,\n",
    "\n",
    "          # Image directory\n",
    "          'train_images_path' : train_images_path,\n",
    "          'validation_images_path' : validation_images_path,\n",
    "          'data_suffix' : data_suffix,\n",
    "          'labels_suffix' : labels_suffix,\n",
    "\n",
    "          # Image pre-processing\n",
    "          'im_prep_params': im_prep_params,\n",
    "          'im_prep_funcs' : im_prep_funcs,\n",
    "          'labels_prep_params' : labels_prep_params,\n",
    "          'labels_prep_funcs' : labels_prep_funcs,\n",
    "          'aug_params' : aug_params,\n",
    "          'aug_funcs' : aug_funcs,\n",
    "\n",
    "          # Training parameters\n",
    "          'n_train_files' : train_generator.n_files,\n",
    "          'n_validation_files' : validation_generator.n_files,\n",
    "          'input_shape' : input_shape,\n",
    "          'n_classes' : n_classes,\n",
    "\n",
    "          'epochs' : epochs,\n",
    "          'shuffle' : shuffle,\n",
    "          'steps_per_epoch' : steps_per_epoch,\n",
    "          'train_batch_size' : train_batch_size,\n",
    "\n",
    "          'validation_batch_size' : validation_batch_size,\n",
    "          'validation_steps' : validation_steps,\n",
    "\n",
    "          'learning_rate' : learning_rate,\n",
    "          'optimizer' : optimizer,\n",
    "          'loss' : loss,\n",
    "          'accuracy' : accuracy,\n",
    "          'class_weights' : class_weights,\n",
    "\n",
    "          'early_stop_steps' : early_stop_steps,\n",
    "          'use_pretreining_imagent' : use_pretreining_imagent,\n",
    "          'freeze' : freeze,\n",
    "\n",
    "          # Outputs\n",
    "          'output_identifier' : base_name,\n",
    "          'weights_output' : path_save_weights\n",
    "          }\n",
    "\n",
    "save_pickle(params, path_save_input_params)\n",
    "\n",
    "print(f'Input parameters saved at: {path_save_input_params}')\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "init = time.time()\n",
    "\n",
    "hist = model.fit_generator(generator=train_generator,\n",
    "                           validation_data=validation_generator,\n",
    "                           epochs=epochs,                               \n",
    "                           validation_steps=validation_steps,\n",
    "                           callbacks = callbacks)\n",
    "endt = time.time()\n",
    "need_time(init, endt)\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the metrics from training process\n",
    "\n",
    "# //-------------------------------------------------------------\\\\\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(12,6)\n",
    "\n",
    "ax[0].plot(hist.history['loss'], color='blue', label='Training')\n",
    "ax[0].plot(hist.history['val_loss'], color='red', label='Validation')\n",
    "ax[1].plot(hist.history['dice_coeff'], color='blue', label='Training')\n",
    "ax[1].plot(hist.history['val_dice_coeff'], color='red', label='Validation')\n",
    "\n",
    "ax[0].set_ylabel('Binary Cross Entropy')\n",
    "ax[0].set_xlabel('Step')\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].set_ylabel('Dice coefficient')\n",
    "ax[1].set_xlabel('Step')\n",
    "ax[1].legend(loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# //-------------------------------------------------------------\\\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
